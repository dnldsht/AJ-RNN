{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels.npy corrisponde alla struttura che contiene le info di classe, oggetto e posizione sulla griglia. Nel caso del codice che ho su github, \n",
    "\n",
    " 0 = row_id, 1 = col_id, 2 = class_id, colonna 3 = object_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from utils import *\n",
    "\n",
    "data = np.load('SITS-Missing-Data/D1_balaruc_samples.npy')\n",
    "masks = np.load('SITS-Missing-Data/D2_balaruc_masks.npy')\n",
    "lut = np.load('SITS-Missing-Data/D3_balaruc_lut.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137606, 54, 16), (137606, 54), (137606, 4))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, masks.shape, lut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_ids_by_class(lut):\n",
    "    labels = lut[:, 1]\n",
    "    unique_labels = np.unique(labels)\n",
    "    ids_by_class = {}\n",
    "    for label in unique_labels:\n",
    "      idx = np.where(labels == label)\n",
    "      lut_subset = lut[idx]\n",
    "      ids_by_class[label] = np.unique(lut_subset[:, 0])\n",
    "    return ids_by_class\n",
    "\n",
    "def get_idx_of_object_ids(ids, lut):\n",
    "    lut_ids = lut[:, 0]\n",
    "    tot_idx = []\n",
    "    for i in ids:\n",
    "        tot_idx.append(np.where(lut_ids == i)[0])\n",
    "    tot_idx = np.concatenate(tot_idx, axis=0)\n",
    "    return tot_idx\n",
    "\n",
    "def get_split_idx(lut, train_perc=.6, val_perc=.2):\n",
    "  train_idx, valid_idx, test_idx = [], [], []\n",
    "  unique_ids_by_class = get_unique_ids_by_class(lut)\n",
    "\n",
    "  for label in unique_ids_by_class:\n",
    "    ids = unique_ids_by_class[label]\n",
    "    ids = shuffle(ids)\n",
    "    \n",
    "    limit_train = int(len(ids)* train_perc )\n",
    "    limit_val = limit_train + int(len(ids)* val_perc)\n",
    "    \n",
    "    train_idx.extend(get_idx_of_object_ids(ids[0:limit_train], lut))\n",
    "    valid_idx.extend(get_idx_of_object_ids(ids[limit_train:limit_val], lut))\n",
    "    test_idx.extend(get_idx_of_object_ids(ids[limit_val::], lut))\n",
    "  return (train_idx,), (valid_idx,), (test_idx,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, val_idx, test_idx = get_split_idx(lut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[np.where(masks == 1)] = MISSING_VALUE\n",
    "\n",
    "num_steps = data.shape[1]\n",
    "num_bands = data.shape[2]\n",
    "labels, num_classes = transfer_labels(lut[:, 1])\n",
    "# labels = convert_to_one_hot(labels, num_classes=len(np.unique(labels)))\n",
    "prediction_target = data[:, 1:]\n",
    "mask = np.ones_like(prediction_target)\n",
    "mask[np.where(prediction_target == MISSING_VALUE)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING RATIO: 0.342\n",
      "MISSING RATIO: 0.330\n",
      "MISSING RATIO: 0.338\n"
     ]
    }
   ],
   "source": [
    "for idx in [train_idx, val_idx, test_idx]:\n",
    "  check_missing_ratio(np.array(mask[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7.3%', '3.7%', '20.5%', '38.8%', '20.9%', '1.5%', '3.5%', '3.7%']\n",
      "['6.9%', '4.8%', '30.9%', '31.4%', '18.3%', '1.1%', '3.4%', '3.2%']\n",
      "['8.9%', '3.0%', '25.1%', '29.8%', '23.1%', '1.9%', '5.0%', '3.1%']\n"
     ]
    }
   ],
   "source": [
    "for idx in [train_idx, val_idx, test_idx]:\n",
    "  l = labels[idx]\n",
    "  _, counts = np.unique(l, return_counts=True)\n",
    "  print([f\"{(c/len(l))*100:.1f}%\" for c in counts])\n",
    "  #print([counts[i]/len(l) for i in range(len(counts))])\n",
    "  #print(np.unique(l, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  5  7  8  9 10 11 13 14 15 16 17 19 21 23 25 26 28 31]\n",
      "[ 1  4  6 18 22 24 27 29 30 36 43 44 47 49 52 61 64 68 71 73]\n",
      "[ 0 12 20 34 38 39 42 46 48 54 66 69 74 76 85 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "for idx in [train_idx, val_idx, test_idx]:\n",
    "  l = lut[idx]\n",
    "  print(np.unique(l[:, 0])[0:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
